Fort Worth

![Image](2013-03-NL_artifacts/image_000000_fff1ccc0e964642e035b294724245af6a92acd89247e6d56e06afdb064931f4d.png)

## Changes

It's a (relatively) new year, new month, new holiday for those with reason to bother,  but  not  a  lot  of  new  news. There are a few updates, such as one for the Odyssey web browser (formerly OW8) for MorphOS. A recent event was an on-line interview with one of the MorphOS  team  programmers.  The exact details of this were less important to  me  than  one  statement,  and  the implications that follow it.

In  the  interview,  a  change  in architecture (as in the hardware and processors that it runs on) was said to be  one  of  the  great  challenges  for MorphOS  in  the  future.  It's  not something  that  can  really  be denied-Power-PC based systems are largely a dead end at this point, even though there's still life and use in G4 and GS-based systems, especially for a light  and  fast  OS  like  Amiga  and MorphOS. Still, sooner or later even the fastest PPC systems will look as dated as 680xO systems do now, and the smart Amiga-like operating systems will have  to  move  to  new  hardware  to survive and keep a shred of relevance, be  it  a  standard  Intel/AMD  PC architecture or something small and streamlined, like the ARM CPU family that powers many of our phones and tablets.  In  any  case,  it's  apparent AmigaOS and/or MorphOS (AROS is already there in one way or another) will have to move on to survive, and we as users will need to decide whether or not to follow. With the speed the small programming teams work though, it will undoubtedly be years before we'll need to worry too much about it.

The other half of the forward-thinking interview  statement  said  the  Amiga software support in MorphOS would need to be dropped to move to these snazzy new future-proof systems. Truth be  told,  the  'legacy'  Amiga compatibility has held MorphOS back to a degree, as classic Amiga software was never intended to support things like advanced memory protection or 64-bit  multicore  CPUs,  and  those limitations work back (or forward) to the more advanced OS for the sake of maintaining  compatibility.  While dropping  the  Amiga  legacy  API  in Morph or OS4 frees them up for bigger and badder hardware support, how many would want to keep with them if the only software available was the stuff specifically written or ported to the OS? For a clue, look to the open-source AROS, which runs on a wide range of hardware,  but  lacks  the  same transparency in Amiga software support that Morph and OS4 currently enjoy. I enjoy using MorphOS now, but at least half or more of the software I use on the system is 'classic' Amiga software without an equivalent written native to the new OS. I'm not sure I would keep with it if that capacity was lost. To be fair, there is a historical precedent for this sort of thing. When Windows and Macintosh  both  had  their  major changes and advances in architecture and operating systems, compatibility with older software suffered, or was dropped entirely. It's fairly laughable to expect your old Windows 3.1 or Mac System 6 software to run properly on the latest and greatest systems, after all. Personally, I doubt Amiga software support will ever be gone completely from MorphOS and OS4, as there is a certain  sense  of  tradition  behind  it. There  probably  will  be  a  few  more added levels of abstraction though than now, with the classic stuff running with a metaphorical protected bubble as its own process, while the main system chugs  along  with  its  terabytes  and multiple cores and whatnot. It would work  much  like  running  an  Amiga emulator now, though hopefully with more of the transparency and system integration of the API used currently.

I have stuck with the Amiga and its descendants  for  decades  now,  and probably will for years yet to come. I have experience with other operating systems, all of which have their own benefits and advantages, but I've never seen  any  that  match  the  sense  of balance of Amiga between ease-of-use, power, and control. Others may have greater power, but they haven't offered much in the way of compelling reasons to move elsewhere. Perhaps the biggest contender in recent times would be my Android tablet. As much as I like the Amiga and MorphOS systems, I'm not sure I would ever be able to use them to work, draw, and more in a package I could hold in my hand while sitting on the  couch.  Maybe  I  just  needed  a whole new paradigm to draw me away from my cozy Amiga complacency, or maybe I'm just playing with a shiny new toy, and will settle back to my usual rut soon enough. Only time will tell.

…by Eric W. Schwartz from the AmiTech Gazette February 2013

## 30 Years Ago…

Analysis: Thirty years ago the modern internet became operational as the US military flipped the switch on TCP/IP, but the move to the protocol stack was nearly killed at birth.

The deadline was 1 January, 1983: after this, any of the Advanced Research Projects  Agency  Network's (ARPANET) 400 hosts that were still clinging to the existing, host-to-host Network Control Protocol (NCP) were to be cut off.

The move to packet switching with TCP/IP  was  simultaneous  and coordinated with the community in the years  before  1983.  More  than  15 government and university institutions from  NASA  AMES  to  Harvard University used NCP on ARPANET.

With so many users, though, there was plenty of disagreement. The deadline was ultimately set because everybody using ARPANET was convinced of the need for wholesale change.

TCP/IP was the co-creation of Vint Cerf and Robert Kahn, who published their paper, A  Protocol  for  Packet  Network Interconnection in 1974.

ARPANET was the wide-area network sponsored by the US Defense Advanced Research Projects Agency (DARPA) that went live in 1969, while Cerf had been an  ARPANET  scientist  at  Stanford University. The military had become interested  in  a  common  protocol  as different networks and systems using different protocols began to hook up to ARPANET and found they couldn't easily talk to each other.

Cerf, who today is vice-president and 'chief  internet  evangelist'  at  Google, announced the 30th anniversary of the TCP/IP switchover in an official Google blog post titled 'Marking the birth of the modern-day Internet.'

The  1983  deadline's  passing  was anticlimactic, Cerf recalls, considering how important TCP/IP became as an enabler for the internet. Cerf writes:

When the day came, it's fair to say the  main  emotion  was  relief, especially amongst those system administrators racing against the clock.  There  were  no  grand celebrations-I can't even find a photograph.  The  only  visible mementos were the 'I survived the TCP/IP switchover' pins proudly worn by those who went through the ordeal!

Yet, with hindsight, it's obvious it was a momentous occasion. On that day, the operational Internet was born.  TCP/IP  went  on  to  be embraced  as  an  international standard, and now underpins the entire Internet.

It was a significant moment, and without TCP/IP we wouldn't have the internet as we know it.

But that wasn't the end of the story, and three years later TCP/IP was in trouble as it suffered from severe congestion to the point of collapse.

TCP/IP had been adopted by the US military in 1980 following successful tests across three separate networks, and when  it  went  live  ARPANET  was managing 400 nodes.

After  the  January  1983  switchover, though, so many computer users were starting to connect to ARPANET-and across ARPANET to other networksthat traffic had started to hit bottlenecks. By  1986  there  were  28,000  nodes chattering across ARPANET, causing congestion with speeds dropping from 32Kbps to 40bps across relatively small distances.

It  fell  to  TCP/IP  contributor  Van Jacobson, who'd spotted the slowdown between his lab in Lawrence Berkeley

## March Calendar

March 4 - Amiga-By-The-Loop Chapter 7:30 PM - Main Grand Prairie Library 901 Conover Drive, Grand Prairie

March 4 - Board of Director's Meeting Approximately 9:15 PM - Location TBD

March 25 - Newsletter Deadline - 8:00 AM

MCCC      4418 Sharpsburg Drive      Grand Prairie, Texas 75052 http://www.amigamccc.org

National Laboratory and the University of  California  at  Berkeley-just  400 yards and two IMP hops apart-to save TCP/IP and the operational internet.

Jacobson  devised  a  congestionavoidance  algorithm  to  lower  a computer's network data transfer speed and  settle  on  a  stable  but  slower connection rather than blindly flooding the network with packets.

The algorithm allowed TCP/IP systems to process lots of requests in a more conservative fashion. The fix was first applied as a client-side patch to PCs by sysadmins and then incorporated into the TCP/IP stack. Jacobson went on to author the Congestion Avoidance and Control (SIGCOMM 88) paper while the internet marched on to about one billion nodes.

And even this is not the end of the story. Years later, in an interview with The Reg, Jacobson  reckoned  TCP/IP  faces another crisis-and, again, it's scalability.

This time, the problem is millions of users surfing towards the same web destinations for the same content, such as a piece of news or video footage on YouTube. Jacobson, a Xerox PARC research fellow and former Cisco chief scientist, told us in 2010 about his work on  Content-Centric  Networking,  a network architecture to cache content locally  to  avoid  everybody  hitting exactly the same servers simultaneously.

- …By Gavin Clarke Posted in Networks 3rd January 2013 URL: http://bit.ly/UIzEQT